{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# CLI Generator\n",
    "\n",
    "Fetches a documentation URL and uses an LLM to generate a Python CLI tool.\n",
    "\n",
    "**Interactive use** – edit the *Parameters* cell below and run all cells.  \n",
    "**Headless use** – `make cli URL=https://... [PROVIDER=claude|hf] [MODEL=...]`\n",
    "\n",
    "Output is saved to `cli/<domain>/<model>/cli.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parameters",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# ── Parameters ────────────────────────────────────────────────────────────────\n",
    "# Edit here for interactive use; overridden automatically by `make cli`.\n",
    "\n",
    "# Provider: \"claude\" or \"hf\"\n",
    "PROVIDER = \"claude\"\n",
    "\n",
    "# Claude models : claude-opus-4-6 | claude-sonnet-4-6 | claude-haiku-4-5-20251001\n",
    "# HF models     : mistralai/Mistral-7B-Instruct-v0.3 | meta-llama/Meta-Llama-3-8B-Instruct\n",
    "MODEL = \"claude-opus-4-6\"\n",
    "\n",
    "# Documentation URL to generate a CLI from\n",
    "URL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport re\nimport time\nfrom pathlib import Path\nfrom urllib.parse import urlparse\n\nimport mlflow\nfrom dotenv import load_dotenv\n\nload_dotenv(dotenv_path=Path(\"../.env\"))  # works from notebooks/ or repo root\nload_dotenv()                              # fallback: CWD .env\n\n# Fall back to environment variables when parameters were not set by papermill\nPROVIDER = PROVIDER or os.getenv(\"PROVIDER\", \"claude\")\nMODEL    = MODEL    or os.getenv(\"MODEL\",    \"claude-opus-4-6\")\nURL      = URL      or os.getenv(\"URL\",      \"\")\n\nassert URL, (\n    \"URL must be set.\\n\"\n    \"  Interactive : edit the Parameters cell above.\\n\"\n    \"  Headless    : make cli URL=https://...\"\n)\n\nprint(f\"Provider : {PROVIDER}\")\nprint(f\"Model    : {MODEL}\")\nprint(f\"URL      : {URL}\")"
  },
  {
   "cell_type": "code",
   "id": "3cb16nxndxr",
   "source": "# ── MLflow tracking setup ──────────────────────────────────────────────────\nMLFLOW_TRACKING_URI = os.environ.get(\"MLFLOW_TRACKING_URI\", \"http://127.0.0.1:5000\")\nmlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\nmlflow.set_experiment(\"cli-generator\")\n\nparsed   = urlparse(URL)\nrun_name = f\"{parsed.netloc}-{MODEL.replace('/', '--')}\"\nmlflow.start_run(run_name=run_name)\nmlflow.log_params({\n    \"provider\": PROVIDER,\n    \"model\":    MODEL,\n    \"url\":      URL,\n})\n\nprint(f\"MLflow tracking URI : {MLFLOW_TRACKING_URI}\")\nprint(f\"Run ID              : {mlflow.active_run().info.run_id}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fetch",
   "metadata": {},
   "outputs": [],
   "source": "import requests\nfrom bs4 import BeautifulSoup\n\nresp = requests.get(URL, timeout=30, headers={\"User-Agent\": \"Mozilla/5.0\"})\nresp.raise_for_status()\n\nsoup = BeautifulSoup(resp.text, \"html.parser\")\nfor tag in soup([\"script\", \"style\", \"nav\", \"footer\", \"header\", \"aside\"]):\n    tag.decompose()\n\npage_text = soup.get_text(separator=\"\\n\", strip=True)\npage_text = \"\\n\".join(line for line in page_text.splitlines() if line.strip())\npage_text = page_text[:12_000]  # keep within model token budget\n\nmlflow.log_metric(\"doc_chars\", len(page_text))\nprint(f\"Fetched {len(page_text):,} chars from {URL}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM = \"You are an expert Python developer. Write clean, idiomatic, production-quality Python code.\"\n",
    "\n",
    "USER = f\"\"\"Based on the documentation below, create a complete, working Python CLI tool using argparse.\n",
    "\n",
    "Requirements:\n",
    "- Implement the main functionality described in the docs\n",
    "- Use argparse with clear --help text for every argument\n",
    "- Include a main() function and `if __name__ == '__main__': main()`\n",
    "- Add concise error handling\n",
    "- Every function must be fully implemented — no placeholders\n",
    "\n",
    "Source: {URL}\n",
    "\n",
    "Documentation:\n",
    "---\n",
    "{page_text}\n",
    "---\n",
    "\n",
    "Respond with ONLY the Python code, starting with the imports.\"\"\"\n",
    "\n",
    "print(f\"Prompt built ({len(USER):,} chars). Calling {PROVIDER}/{MODEL}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm",
   "metadata": {},
   "outputs": [],
   "source": "t0 = time.perf_counter()\n\nif PROVIDER == \"claude\":\n    import anthropic\n\n    client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n    response = client.messages.create(\n        model=MODEL,\n        max_tokens=4096,\n        system=SYSTEM,\n        messages=[{\"role\": \"user\", \"content\": USER}],\n    )\n    raw = response.content[0].text\n\nelif PROVIDER == \"hf\":\n    from huggingface_hub import InferenceClient\n\n    client = InferenceClient(token=os.getenv(\"HF_TOKEN\"))\n    result = client.chat.completions.create(\n        model=MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM},\n            {\"role\": \"user\",   \"content\": USER},\n        ],\n        max_tokens=2048,\n        temperature=0.1,\n    )\n    raw = result.choices[0].message.content\n\nelse:\n    raise ValueError(f\"Unknown PROVIDER '{PROVIDER}'. Use 'claude' or 'hf'.\")\n\nlatency_s = time.perf_counter() - t0\nmlflow.log_metrics({\n    \"latency_s\":      round(latency_s, 3),\n    \"response_chars\": len(raw),\n})\n\nprint(f\"Received {len(raw):,} chars in {latency_s:.1f}s.\")\nprint(raw[:800] + (\"\\n...\" if len(raw) > 800 else \"\"))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save",
   "metadata": {},
   "outputs": [],
   "source": "# Strip markdown code fences if the model wrapped the code\ncode_match = re.search(r\"```(?:python)?\\n(.*?)```\", raw, re.DOTALL)\ncli_code = code_match.group(1).strip() if code_match else raw.strip()\n\n# Output path: cli/<domain>/<model-slug>/cli.py\ndomain     = urlparse(URL).netloc.lstrip(\"www.\")\nmodel_slug = MODEL.replace(\"/\", \"_\").replace(\":\", \"_\")\n\n# Use CWD-relative path (works from repo root for both jupyter and papermill)\nout_dir = Path(\"cli\") / domain / model_slug\nout_dir.mkdir(parents=True, exist_ok=True)\n\nout_path = out_dir / \"cli.py\"\nout_path.write_text(cli_code, encoding=\"utf-8\")\n\nmlflow.log_metric(\"cli_chars\", len(cli_code))\nmlflow.log_artifact(str(out_path.resolve()), artifact_path=\"generated\")\nmlflow.end_run()\n\nprint(f\"\\nCLI tool saved  → {out_path.resolve()}\")\nprint(f\"Run with        : python {out_path} --help\")\nprint(f\"MLflow UI       : {MLFLOW_TRACKING_URI}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}